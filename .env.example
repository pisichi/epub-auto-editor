### program settings ###
# Input and output folders
INPUT_FOLDER = "input"
OUTPUT_FOLDER = "output"
# Cache and verbosity settings
NO_CACHE = False
VERBOSE = False
# your agent URL
LLAMA_URL = http://example.llm-agent-url:8083/generate

#### llama.cpp model settings, wil be ignored if MODEL_PATH is not provided ####
MODEL_PATH = model/example_model.gguf  # If this has a value, the URL will be ignored
N_GPU_LAYERS = -1
N_CTX = 2048
N_BATCH = 32
TEMPERATURE=0.4
REPEAT_PENALTY=1.0
# Editor's prompt and message formatting
AGENT_PROMPT = You are a professional editor. Your job is to fix grammar in the given paragraph to enhance its quality.
PREDEFINED_MESSAGES_FORMATTER_TYPE = CHATML
# Debugging option
DEBUG_MODEL_OUTPUT = False